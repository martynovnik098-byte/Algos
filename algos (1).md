Я подготовил подробные ответы на все вопросы, опираясь на предоставленные лекции. Там, где темы (например, хеш-таблицы или бинарные деревья поиска) отсутствовали в лекциях, я добавил общепринятую теорию, необходимую для сдачи экзамена.

---

# Основные вопросы

### 1. Как оценить эффективность алгоритма? Что такое асимптотическая сложность алгоритма?

**Ответ:**
Эффективность алгоритма оценивается не в секундах, а в том, как растет потребление ресурсов (времени и памяти) при увеличении объема входных данных ($n$).
Измерять время в секундах некорректно, так как оно зависит от мощности компьютера, языка программирования и загруженности системы (Лекция 1).

**Асимптотическая сложность** — это функция, описывающая предельное поведение алгоритма при стремлении размера входных данных к бесконечности ($n \to \infty$).
Мы отбрасываем константы и менее значимые слагаемые, оставляя только ту часть формулы, которая растет быстрее всего.
*   **Пример:** Если время работы $T(n) = 100n^2 + 50n + 3$, то при огромных $n$ слагаемое $100n^2$ будет настолько большим, что остальными можно пренебречь. Асимптотическая сложность будет $O(n^2)$.

### 2. Выразите функцию в тета-обозначениях.

**Задача (по мотивам Кормена):** Дана функция, например, $f(n) = \frac{n^3}{1000} - 100n^2 - 100n + 3$. Нужно выразить её через $\Theta$.

**Ответ:** $\Theta(n^3)$.

**Разбор:**
Обозначение $\Theta$ (Тета) означает точную асимптотическую оценку (функция зажата между верхним и нижним пределами).
Чтобы её найти:
1.  Смотрим на слагаемое с самой высокой степенью $n$. В данном случае это $n^3$.
2.  Отбрасываем все коэффициенты (множитель $1/1000$) и все слагаемые с меньшими степенями ($-100n^2$, $-100n$ и т.д.), так как при $n \to \infty$ они становятся ничтожно малы по сравнению с кубом.
3.  Остается $n^3$.

### 3. Поиск элемента в массиве (неотсортированном и отсортированном).

**А. Неотсортированный массив**
*   **Алгоритм:** Линейный поиск (Linear Search). Идем от первого элемента к последнему (Лекция 1, 2).
*   **Сложность:**
    *   *Лучший случай:* $O(1)$ — искомый элемент оказался первым.
    *   *Худший случай:* $O(n)$ — элемента нет или он последний. Приходится проверить все $n$ элементов.
    *   *Средний случай:* $O(n)$ — элемент где-то в середине ($n/2$ проверок, константа 1/2 отбрасывается).

**Б. Отсортированный массив**
*   **Алгоритм:** Бинарный поиск (Binary Search). Упоминается в Лекции 3 (сортировка вставками).
*   **Принцип:** Берем элемент посередине. Если искомое меньше — ищем в левой половине, если больше — в правой. Каждый шаг отсекает половину массива.
*   **Сложность:**
    *   *Лучший случай:* $O(1)$ — сразу попали в середину.
    *   *Худший случай:* $O(\log n)$ — делим массив пополам, пока не останется 1 элемент.
    *   *Средний случай:* $O(\log n)$.

**Обоснование:** Логарифм растет намного медленнее линии. Для 1 миллиона элементов линейный поиск сделает 1 000 000 проверок, а бинарный — около 20 (так как $2^{20} \approx 10^6$).

### 4. Расположите функции по скорости их асимптотического роста.

От самого быстрого (наименее затратного) к самому медленному (Лекция 1, график):

1.  **$O(1)$** — константное время (мгновенно).
2.  **$O(\lg n)$** — логарифмическое время (бинарный поиск).
3.  **$O(n)$** — линейное время (проход по массиву).
4.  **$O(n \lg n)$** — линейно-логарифмическое (быстрая сортировка, сортировка слиянием - Лекция 3).
5.  **$O(n^2)$** — квадратичное время (сортировка пузырьком/вставками, вложенные циклы).

### 5. Сравнение динамического массива (vector) и связного списка (list).

(Лекции 2 и 3)

| Характеристика | Динамический массив (`std::vector`) | Связный список (`std::list`) |
| :--- | :--- | :--- |
| **Структура памяти** | Единый непрерывный блок памяти. | Разбросанные узлы, связанные указателями. |
| **Доступ к элементу** | **$O(1)$** (по индексу `v[i]`). | **$O(n)$** (надо пройти по цепочке ссылок). |
| **Вставка в конец** | **$O(1)$** (амортизированное). | **$O(1)$**. |
| **Вставка в середину** | **$O(n)$** (нужно сдвигать хвост массива). | **$O(1)$** (если уже есть итератор на позицию). |
| **Кэш-локальность** | Высокая (данные рядом, процессор доволен). | Низкая (скачки по памяти). |

**Когда использовать:**
*   **Vector:** Почти всегда. Когда нужен быстрый доступ по индексу и добавление данных в конец.
*   **List:** Когда нужно часто вставлять/удалять элементы в *середину* списка и не нужен доступ по индексу (например, `list[5]`).

### 6. Словарь на хеш-таблице (Hash Map).

*(В лекциях нет, объясняю теорию)*

**Принцип:** Массив списков (или "корзин").
1.  Берем ключ $\to$ Хеш-функция превращает его в число (хеш).
2.  Индекс в массиве = `hash % array_size`.
3.  Кладем пару (ключ, значение) в полученную ячейку.

**Коллизии:** Если у разных ключей совпал индекс, элементы хранятся в виде связного списка в этой ячейке (метод цепочек).

**Сложность:**
*   **Вставка/Поиск/Удаление:**
    *   *Лучший/Средний:* **$O(1)$**. Мы сразу вычисляем адрес и идем туда.
    *   *Худший:* **$O(n)$**. Если хеш-функция плохая, все элементы попадут в одну ячейку. Таблица выродится в длинный связный список.

### 7. Словарь на бинарном дереве поиска (BST).

*(В лекциях нет, объясняю теорию)*

**Принцип:** Дерево, где у каждого узла есть ключ.
*   Все ключи в *левом* поддереве **меньше** текущего.
*   Все ключи в *правом* поддереве **больше** текущего.

**Операции:** Сравниваем искомое с корнем. Меньше — идем влево, больше — вправо.

**Сложность:**
Зависит от высоты дерева ($h$).
*   *Средний (сбалансированное дерево):* **$O(\log n)$**.
*   *Худший (дерево выродилось в линию):* **$O(n)$**. Это происходит, если добавлять отсортированные данные (1, 2, 3...) в обычное BST.

### 8. Множество на бинарном дереве поиска.

**Принцип:** То же самое, что и словарь (вопрос 7), только храним **только ключи** (без значений). Главное свойство множества — уникальность элементов.

**Операции (Вставка/Удаление/Поиск):**
Алгоритм идентичен. При вставке проверяем: если дошли до узла с таким же значением — ничего не делаем (дубликаты запрещены).
**Сложность:** $O(\log n)$ в среднем, $O(n)$ в худшем.

### 9. Множество на хеш-таблице.

**Принцип:** То же самое, что и словарь (вопрос 6), храним **только ключи**. Хеш считается от самого элемента.

**Операции:** Вычислили хеш $\to$ проверили ячейку.
**Сложность:** $O(1)$ в среднем, $O(n)$ в худшем (при коллизиях).

### 10. Стек и Очередь.

(Лекция 4)

**Стек (Stack):**
*   **Принцип:** LIFO (Last In — First Out). "Стопка тарелок".
*   **Операции:** `push` (добавить наверх), `pop` (снять сверху), `top/back` (посмотреть верхний). Все **$O(1)$**.
*   **Реализация:** Динамический массив (`std::vector`), связный список (`std::list`).

**Очередь (Queue):**
*   **Принцип:** FIFO (First In — First Out). "Очередь в кассу".
*   **Операции:** `push/enqueue` (в хвост), `pop/dequeue` (из головы), `front` (посмотреть первого). Все **$O(1)$**.
*   **Реализация:** Связный список (`std::list`), двусторонняя очередь (`std::deque`). `std::vector` плох, так как удаление из начала стоит $O(n)$.

---

# Дополнительные вопросы

### 1. Какова алгоритмическая сложность оператора произвольного доступа `[]` у `std::vector`? Почему?
**Ответ:** **$O(1)$**.
**Почему:** Вектор — это непрерывный кусок памяти. Зная адрес начала (`begin`) и размер элемента (`sizeof`), адрес $i$-го элемента вычисляется простой арифметикой:
`Адрес = begin + i * sizeof(T)`. Это одно вычисление, независимо от размера вектора (Лекция 2).

### 2. Что быстрее: пройтись по `std::vector` или по `std::list`? Почему?
**Ответ:** Быстрее пройтись по **`std::vector`**.
**Почему:** Элементы вектора лежат в памяти подряд. Процессор может загружать их в кэш целыми пачками (prefetching). У списка элементы разбросаны по памяти хаотично, что приводит к частым промахам кэша (cache misses). (Упоминается в Лекции 3).

### 3. Что быстрее: вставить $10^7$ элементов в пустой `std::vector` или в пустой `std::list`?
**Ответ:** В **`std::vector`** (при условии использования `reserve`).
**Почему:**
*   В списке (`list`) для **каждого** элемента вызывается системная функция выделения памяти (`new` / `malloc`), что очень дорого.
*   В векторе, если сделать `reserve(10^7)`, память выделится один раз, и элементы просто запишутся подряд. Даже без `reserve` вектор выделяет память редко (блоками), что все равно быстрее.

### 4. Сложность вставки элемента в конец вектора.
**Ответ:** **$O(1)$ амортизированная**.
Обычно это просто запись в следующую ячейку. Редко, когда место кончается, вектор создает новый массив в 2 раза больше, копирует данные и удаляет старый. Если "размазать" это долгое копирование по всем быстрым вставкам, в среднем получается константа.

### 5. Сложность вставки элемента в начало вектора.
**Ответ:** **$O(n)$**.
Нужно сдвинуть **все** существующие $n$ элементов на одну позицию вправо, чтобы освободить нулевую ячейку.

### 6. Сложность вставки элемента в середину вектора.
**Ответ:** **$O(n)$**.
В среднем нужно сдвинуть половину элементов ($n/2$), что асимптотически равно $O(n)$.

### 7. Сложность удаления элемента из конца вектора.
**Ответ:** **$O(1)$**.
Мы просто уменьшаем счетчик размера вектора (`size`). Физически память чистить не обязательно (Лекция 2).

### 8. Сложность удаления элемента из середины вектора.
**Ответ:** **$O(n)$**.
Обратная операция вставке: нужно сдвинуть весь "хвост" влево, чтобы закрыть образовавшуюся дырку.

### 9. Можно ли удалить произвольный элемент из вектора за O(1), если порядок не важен?
**Ответ:** **Да.**
**Как:**
1.  Берем удаляемый элемент.
2.  Меняем его местами с **последним** элементом вектора (`std::swap(v[i], v.back())`).
3.  Делаем `pop_back()` (удаляем последний).
Порядок нарушится, зато никаких сдвигов массива.

### 10. Задача про подсчет чисел (Count Sort / Frequency Array).
**Условие:** Числа от 1 до 1000, $N = 10^{10}$ (очень много чисел, массив не сохранить).
**Решение:**
Нам не нужно хранить сами числа. Нам нужно знать, сколько раз встретилось каждое.
1.  Создаем массив счетчиков размером 1001 (индексы 0..1000): `int counts[1001] = {0};`.
2.  Считываем числа по одному.
3.  Для каждого числа `x` увеличиваем счетчик: `counts[x]++`.
4.  В конце выводим ненулевые значения массива `counts`.
**Память:** $O(1)$ (так как размер массива счетчиков фиксирован и мал — 1000 int'ов).
**Время:** $O(N)$ (один проход по входным данным).

### 11. Для чего нужен метод `reserve()` у `std::vector`?
**Ответ:** Чтобы заранее выделить память под ожидаемое количество элементов.
Это позволяет:
1.  Избежать множественных перевыделений памяти (reallocations) при росте вектора.
2.  Избежать лишних копирований старых элементов в новое место.
Метод меняет `capacity` (емкость), но не меняет `size` (размер) (Лекция 2).

### 12. Что такое `std::unordered_map`? Для чего у него есть метод `reserve()`?
**Ответ:**
*   `std::unordered_map` — это реализация хеш-таблицы в C++ (словарь).
*   Метод `reserve(n)` здесь нужен, чтобы заранее подготовить достаточное количество "корзин" (buckets) для хранения $n$ элементов.
*   Это предотвращает **rehashing** (перехеширование) — дорогостоящую операцию, когда таблица увеличивается, и все ключи нужно заново распределять по новым ячейкам.
